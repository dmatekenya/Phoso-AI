{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from sqlalchemy import create_engine, MetaData\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain.chains import create_sql_query_chain, LLMChain\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.evaluation import load_evaluator, EmbeddingDistance\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = config(\"OPENAI_API_KEY\")\n",
    "DB_USER = config('DB_USER')\n",
    "DB_PASSWORD = config('DB_PASSWORD')\n",
    "DB_HOST = 'localhost'\n",
    "DB_PORT = '5432'\n",
    "DB_NAME = \"food_security\"\n",
    "SAMPLE_QUESTIONS = {\"low-birthweight\": \"Which region has the highest number of children born with low birth weights?\",\n",
    "                    \"vaccine_rates\": \"Which vaccine has the lowest vaccination percentage?\",\n",
    "                    \"vaccine_rates_all\": \"What percentage of children received all vaccines before 12 months\",\n",
    "                    \"kids_in_sch\": \"Whats average percentage of children who are in preschool\",\n",
    "                    \"vaccines\": \"which vaccines did children get in Tunisia?\"\n",
    "                    }\n",
    "                    \n",
    "# Create the database URL\n",
    "DATABASE_URL = f'postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}'\n",
    "FILE_SQL_EXAMPLES_EN = \"sql_examples_en.json\"\n",
    "USE_BEST_MATCHING_COLUMNS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Prompt to Select best Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_database(database_url=DATABASE_URL):\n",
    "    \"\"\"Connects to a postgreSQL\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    database_url : String\n",
    "        postgreSQL database connection URL, by default DATABASE_URL\n",
    "    \"\"\"\n",
    "    # conn = psycopg2.connect(f\"dbname={DB_NAME} user={DB_USER} password={DB_PASSWORD}\")\n",
    "    conn = psycopg2.connect(database_url)\n",
    "\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Query to get table names and column names\n",
    "    cur.execute(\"SELECT table_name, description FROM table_metadata\")\n",
    "    tables = cur.fetchall()\n",
    "\n",
    "    cur.execute(\"SELECT table_name, column_name, description FROM column_metadata\")\n",
    "    columns = cur.fetchall()\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "    return tables, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_table_prompt(user_query, tables, columns, \n",
    "                           return_chain=True, llm=None):# Define the template for selecting the best table\n",
    "    template = \"\"\"\n",
    "    You are a database assistant. Given the following tables and columns with their descriptions, select the best table that matches the user's query.\n",
    "\n",
    "    Tables and Columns:\n",
    "    {table_info}\n",
    "\n",
    "    User Query:\n",
    "    {user_query}\n",
    "\n",
    "    Provide the output in the following JSON format:\n",
    "    {{\n",
    "        \"best_matching_table\": {{\n",
    "            \"table_name\": \"<best_table_name>\",\n",
    "            \"description\": \"<best_table_description>\"\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    # Prepare the table_info string including descriptions for each table and its columns\n",
    "    table_info = \"\"\n",
    "    for table in tables:\n",
    "        table_name, table_description = table\n",
    "        table_info += f\"Table: {table_name} - {table_description}\\n\"\n",
    "        table_columns = [col for col in columns if col[0] == table_name]\n",
    "        for column in table_columns:\n",
    "            _, column_name, column_description = column\n",
    "            table_info += f\"    Column: {column_name} - {column_description}\\n\"\n",
    "        table_info += \"\\n\"\n",
    "\n",
    "    # Create the PromptTemplate\n",
    "    prompt_template = PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"table_info\", \"user_query\"]\n",
    "    )\n",
    "\n",
    "    # Format the template \n",
    "    formatted_prompt = prompt_template.format(table_info=table_info, user_query=user_query)\n",
    "\n",
    "    if return_chain:\n",
    "        # Create the chain using the ChatOpenAI model and the PromptTemplate\n",
    "        chain = LLMChain(llm=llm,prompt=prompt_template)\n",
    "        return chain, {\"table_info\": table_info, \"user_query\": user_query}\n",
    "\n",
    "    return formatted_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_info(table_name, columns):\n",
    "    columns_info = \"\"\n",
    "    for column in columns:\n",
    "        table, column_name, column_description = column\n",
    "        if table == table_name:\n",
    "            columns_info += f\"    Column: {column_name} - {column_description}\\n\"\n",
    "    return columns_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_columns_prompt(user_query, best_matching_table, columns, \n",
    "                       return_chain=True, llm=None):\n",
    "    # Define the template for selecting the relevant columns\n",
    "    column_template = \"\"\"\n",
    "    You are a database assistant. Given the following columns for the table '{table_name}', select the columns that are most relevant to the user's query.\n",
    "\n",
    "    Table Description: {table_description}\n",
    "\n",
    "    Columns:\n",
    "    {columns_info}\n",
    "\n",
    "    User Query:\n",
    "    {user_query}\n",
    "\n",
    "    Relevant Columns:\n",
    "    \"\"\"\n",
    "\n",
    "    columns_info = get_columns_info(best_matching_table[\"table_name\"], columns)\n",
    "\n",
    "    # Create the PromptTemplate for column selection\n",
    "    column_prompt_template = PromptTemplate(\n",
    "        template=column_template,\n",
    "        input_variables=[\"table_name\", \"table_description\", \"columns_info\", \"user_query\"]\n",
    "    )\n",
    "\n",
    "    # Example usage of the template with a user query\n",
    "    formatted_column_prompt = column_prompt_template.format(\n",
    "        table_name=best_matching_table[\"table_name\"],\n",
    "        table_description=best_matching_table[\"description\"],\n",
    "        columns_info=columns_info,\n",
    "        user_query=user_query\n",
    "    )\n",
    "\n",
    "    # Prepare the context for running the chain\n",
    "    context = {\n",
    "        \"table_name\": best_matching_table[\"table_name\"],\n",
    "        \"table_description\": best_matching_table[\"description\"],\n",
    "        \"columns_info\": columns_info,\n",
    "        \"user_query\": user_query}\n",
    "\n",
    "    if return_chain:\n",
    "        chain = LLMChain(llm=llm,prompt=column_prompt_template)\n",
    "        return chain, context\n",
    "\n",
    "    return formatted_column_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sql_examples(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sql_prompt(examples, best_matching_table, columns_metadata, \n",
    "                      use_best_matching_columns=False, llm=None):\n",
    "    \"\"\"\n",
    "    Creates a FewShotPromptTemplate for generating SQL queries based on table and column metadata.\n",
    "\n",
    "    This function generates a prompt template that includes detailed information about the table and its columns.\n",
    "    The generated prompt instructs a language model (LLM) to create a syntactically correct SQL query based on\n",
    "    user input. If the table contains a date column and the user does not specify a date, the prompt also instructs\n",
    "    the LLM to retrieve the most recent data available.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    examples : list of dict\n",
    "        A list of example inputs and corresponding SQL queries. Each example should be a dictionary with 'input' and 'query' keys.\n",
    "    best_matching_table : dict\n",
    "        A dictionary containing the best matching table information with 'table_name' and 'description' keys.\n",
    "    columns_metadata : list of tuples\n",
    "        A list of tuples containing columns metadata. Each tuple should include 'table_name', 'column_name', and 'description'.\n",
    "    use_best_matching_columns : bool, optional\n",
    "        A flag indicating whether to use only the best-matching columns (if True) or all columns in the table (if False). Default is True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sql_prompt : FewShotPromptTemplate\n",
    "        A FewShotPromptTemplate object that can be used with an LLM to generate SQL queries.\n",
    "    \"\"\"\n",
    "    # Prepare table_info string based on the best matching table and columns\n",
    "    # table_info = f\"Table: {best_matching_table['table_name']} - {best_matching_table['description']}\\n\"\n",
    "    columns_info = \"Columns:\\n\"\n",
    "    has_date_column = False\n",
    "\n",
    "    # Determine which columns to use: best-matching or all columns\n",
    "    if use_best_matching_columns:\n",
    "        # If using best_matching_columns, use those provided (filtering columns_metadata based on matching logic)\n",
    "        columns_to_use = columns_metadata  # Assuming columns_metadata is already filtered\n",
    "    else:\n",
    "        # Use all columns for the given table from columns_metadata\n",
    "        columns_to_use = [col for col in columns_metadata if col[0] == best_matching_table['table_name']]\n",
    "\n",
    "    # Construct the columns_info string\n",
    "    for column in columns_to_use:\n",
    "        table_name, column_name, column_description = column\n",
    "        columns_info += f\"    Column: {column_name} - {column_description}\\n\"\n",
    "        if 'date' in column_name.lower():\n",
    "            has_date_column = True\n",
    "\n",
    "    # Create FewShot Prompt with instructions for handling most recent data\n",
    "    example_prompt = PromptTemplate.from_template(\"User input: {input}\\nSQL query: {query}\")\n",
    "\n",
    "    # Add a special instruction if the table has a date column\n",
    "    recent_data_instruction = (\n",
    "        \"If the user does not specify a date, retrieve the most recent data available by ordering the results \"\n",
    "        \"by the date column in descending order.\"\n",
    "    ) if has_date_column else \"\"\n",
    "\n",
    "    # Combine table_info and columns_info in the prompt\n",
    "    sql_prompt = FewShotPromptTemplate(\n",
    "        examples=examples,\n",
    "        example_prompt=example_prompt,\n",
    "        prefix=(\n",
    "            \"You are a PostgreSQL expert. Given an input question, create a syntactically correct PostgreSQL query to run. \"\n",
    "            \"Unless otherwise specified, do not return more than {top_k} rows.\\n\\n\"\n",
    "            \"Here is the relevant table information:\\n{table_info}\\n\\n\"\n",
    "            f\"{recent_data_instruction}\\n\\n\"\n",
    "            \"Below are a number of examples of questions and their corresponding SQL queries.\"\n",
    "        ),\n",
    "        suffix=\"User input: {input}\\nSQL query: \",\n",
    "        input_variables=[\"input\", \"table_info\", \"top_k\"],\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return sql_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import FewShotPromptTemplate\n",
    "\n",
    "def create_custom_sql_query_chain(llm, db, examples, best_matching_table, columns_metadata, use_best_matching_columns=False):\n",
    "    \"\"\"\n",
    "    Custom function to create an SQL query chain using the provided LLM and SQL prompt.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    llm : Any\n",
    "        The language model (e.g., ChatOpenAI) to be used for generating the SQL query.\n",
    "    db : SQLDatabase\n",
    "        The database object for executing the generated SQL queries.\n",
    "    examples : list of dict\n",
    "        A list of example inputs and corresponding SQL queries.\n",
    "    best_matching_table : dict\n",
    "        A dictionary containing the best matching table information with 'table_name' and 'description' keys.\n",
    "    columns_metadata : list of tuples\n",
    "        A list of tuples containing columns metadata.\n",
    "    use_best_matching_columns : bool, optional\n",
    "        A flag indicating whether to use only the best-matching columns or all columns in the table. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    write_query : LLMChain\n",
    "        An LLMChain object ready to generate and execute SQL queries based on user input.\n",
    "    \"\"\"\n",
    "    # Generate the sql_prompt using the provided function\n",
    "    sql_prompt = create_sql_prompt(\n",
    "        examples=examples, \n",
    "        best_matching_table=best_matching_table, \n",
    "        columns_metadata=columns_metadata,\n",
    "        use_best_matching_columns=use_best_matching_columns\n",
    "    )\n",
    "\n",
    "    # Create the LLMChain manually\n",
    "    return LLMChain(llm=llm, prompt=sql_prompt)\n",
    "\n",
    "# Initialize LLM and other components\n",
    "engine = create_engine(DATABASE_URL)\n",
    "db = SQLDatabase(engine=engine, ignore_tables=['table_metadata', 'column_metadata'])\n",
    "\n",
    "# Use the custom wrapper to create the chain\n",
    "write_query = create_custom_sql_query_chain(\n",
    "    llm=llm,\n",
    "    db=db,\n",
    "    examples=examples,\n",
    "    best_matching_table=best_table_output,\n",
    "    columns_metadata=best_columns_output if USE_BEST_MATCHING_COLUMNS else columns,\n",
    "    use_best_matching_columns=USE_BEST_MATCHING_COLUMNS\n",
    ")\n",
    "\n",
    "# Create the answer chain\n",
    "answer_chain = create_answer_chain(llm)\n",
    "\n",
    "# Put everything together\n",
    "master_chain = (\n",
    "    RunnablePassthrough.assign(query=write_query).assign(\n",
    "        result=itemgetter(\"query\") | execute_query\n",
    "    )\n",
    "    | answer_chain\n",
    ")\n",
    "\n",
    "# Invoke the master chain with the required inputs\n",
    "response = master_chain.invoke({\n",
    "    \"input\": user_question,  # This is your user query\n",
    "    \"top_k\": 10              # You can adjust this value as needed for the number of rows to return\n",
    "})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_answer_chain(llm):\n",
    "    # Define the prompt template with emphasis on including units, time-specific details, and using the latest data when time is not specified\n",
    "    answer_prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        You are a knowledgeable assistant. Given the following user question and SQL result, answer the question accurately.\n",
    "        \n",
    "        Always ensure to:\n",
    "        1. Include appropriate units in your answer (e.g., Kwacha per kg, liters, etc.).\n",
    "        2. Specify the time period or date if the question implies or explicitly asks for it.\n",
    "        3. If the user does not specify a time, provide the most recent information available in the database and clearly state that this is the latest data.\n",
    "\n",
    "        For example, if the user asks \"What's the price of Maize?\", your answer should include the price with the correct unit and mention that this is the most recent price, e.g., \"The most recent price of Maize is 60 Kwacha per kg.\"\n",
    "        If the user asks about a specific time period, such as \"What's the price of Maize for May 2024?\", include the time in your answer, e.g., \"The price of Maize in May 2024 is 60 Kwacha per kg.\"\n",
    "\n",
    "        Question: {question}\n",
    "        SQL Result: {result}\n",
    "        Answer: \"\"\"\n",
    "    )\n",
    "\n",
    "    return answer_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sql_chain(user_query, best_table_info, columns_info, best_columns=None, llm=None):\n",
    "    \"\"\"\n",
    "    Executes an SQL query generation chain using a language model (LLM) based on the user query, \n",
    "    best matching table, and columns information.\n",
    "\n",
    "    This function loads example SQL queries, creates an SQL prompt tailored to the best matching \n",
    "    table and its columns, and then executes a chain that generates and executes an SQL query. \n",
    "    The response is returned after processing the generated query.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    user_query : str\n",
    "        The user's query for which an SQL query needs to be generated.\n",
    "    best_table_info : dict\n",
    "        A dictionary containing the best matching table information with 'table_name' and 'description' keys.\n",
    "    columns_info : list of tuples\n",
    "        A list of tuples containing columns metadata for the table. Each tuple includes 'table_name', \n",
    "        'column_name', and 'description'.\n",
    "    best_columns : list of tuples, optional\n",
    "        A list of tuples containing the best matching columns metadata, if available. If provided, \n",
    "        the SQL prompt will be generated using only these columns. Default is None.\n",
    "    llm : Any, optional\n",
    "        The language model (e.g., ChatOpenAI) to be used for generating the SQL query. Default is None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    response : Any\n",
    "        The response from the executed SQL query chain, typically containing the results of the SQL query.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    response = run_sql_chain(\n",
    "        user_query=\"What is the price of maize?\",\n",
    "        best_table_info={\"table_name\": \"maize_prices\", \"description\": \"Contains maize price data\"},\n",
    "        columns_info=[(\"maize_prices\", \"price\", \"Price of maize\"), (\"maize_prices\", \"date\", \"Date of the price entry\")],\n",
    "        llm=ChatOpenAI()\n",
    "    )\n",
    "    print(response)\n",
    "    \"\"\"\n",
    "    # Load examples and create prompts\n",
    "    examples = load_sql_examples(file_path=FILE_SQL_EXAMPLES_EN)\n",
    "    \n",
    "    # Create SQL Query\n",
    "    if USE_BEST_MATCHING_COLUMNS and best_columns:\n",
    "        sql_prompt = create_sql_prompt(\n",
    "            examples=examples, \n",
    "            best_matching_table=best_table_info, \n",
    "            columns_metadata=best_columns, \n",
    "            use_best_matching_columns=True\n",
    "        )\n",
    "    else:\n",
    "        sql_prompt = create_sql_prompt(\n",
    "            examples=examples, \n",
    "            best_matching_table=best_table_info, \n",
    "            columns_metadata=columns_info\n",
    "        )\n",
    "\n",
    "    # Initialize LLM and other components\n",
    "    best_table = best_table_info['table_name']\n",
    "    engine = create_engine(DATABASE_URL)\n",
    "    db = SQLDatabase(engine=engine, ignore_tables=['table_metadata', 'column_metadata'])\n",
    "\n",
    "    execute_query = QuerySQLDataBaseTool(db=db)\n",
    "    write_query = create_sql_query_chain(llm, db, sql_prompt)\n",
    "\n",
    "    # Create the answer chain\n",
    "    answer_chain = create_answer_chain(llm)\n",
    "\n",
    "    # Put everything together\n",
    "    master_chain = (\n",
    "        RunnablePassthrough.assign(query=write_query).assign(\n",
    "            result=itemgetter(\"query\") | execute_query\n",
    "        )\n",
    "        | answer_chain\n",
    "    )\n",
    "\n",
    "    # Invoke the master chain and return the response\n",
    "    response = master_chain.invoke({\n",
    "        \"question\": user_query, \n",
    "        \"top_k\": 3,\n",
    "        \"table_info\": best_table\n",
    "    })\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sql_query(user_question, use_huggingface=False):\n",
    "    \"\"\"\n",
    "    Processes a user's question by generating and executing an SQL query using a language model (LLM). \n",
    "    Optionally, uses a Hugging Face model or defaults to OpenAI's GPT-3.5-turbo.\n",
    "\n",
    "    This function first initializes the appropriate LLM based on the `use_huggingface` flag. It then \n",
    "    retrieves metadata information, identifies the best matching table and relevant columns, and \n",
    "    executes the SQL query based on the processed information.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    user_question : str\n",
    "        The user's question for which an SQL query needs to be generated and executed.\n",
    "    use_huggingface : bool, optional\n",
    "        A flag to determine whether to use a Hugging Face model instead of the default OpenAI model. \n",
    "        Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : Any\n",
    "        The output from the executed SQL query chain, typically containing the results of the SQL query.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    output = process_sql_query(\n",
    "        user_question=\"What is the price of maize?\",\n",
    "        use_huggingface=False\n",
    "    )\n",
    "    print(output)\n",
    "    \"\"\"\n",
    "    # Initialize LLM\n",
    "    # To Do: add Hugging Face LLM\n",
    "    if use_huggingface:\n",
    "        pass  # Hugging Face LLM initialization can be added here\n",
    "    else:\n",
    "        openai_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "   \n",
    "    # Retrieve the metadata info (tables and columns)\n",
    "    tables, columns = connect_to_database()\n",
    "\n",
    "    # Chain 1: Find the Best Table\n",
    "    best_table_chain, context = find_best_table_prompt(user_question, tables, columns, llm=openai_llm)\n",
    "    best_table_output_str = best_table_chain.run(**context)\n",
    "\n",
    "    # Convert the string output to a dictionary\n",
    "    try:\n",
    "        best_table_output = json.loads(best_table_output_str)['best_matching_table']\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: The output is not valid JSON.\")\n",
    "        best_table_output = None\n",
    "\n",
    "    # Chain 2: Find Relevant Columns\n",
    "    best_columns_chain, context = find_best_columns_prompt(user_question, best_table_output, columns, llm=openai_llm)\n",
    "    best_columns_output = best_columns_chain.run(**context)\n",
    "\n",
    "    # Retrieve result \n",
    "    output = run_sql_chain(\n",
    "        user_query=user_question, \n",
    "        best_table_info=best_table_output, \n",
    "        columns_info=columns, \n",
    "        best_columns=best_columns_output, \n",
    "        llm=openai_llm\n",
    "    )\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent price of Maize in Rumphi is 764.45 Kwacha.\n"
     ]
    }
   ],
   "source": [
    "question = \"Whats the price of Maize in Rumphi?\"\n",
    "response = process_sql_query(user_question=question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The most recent price of Maize in Rumphi is 764.445 Kwacha.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_embedding_distance(df, lan='English', \n",
    "                                     distance='cosine', ref_response_col='response-1'):\n",
    "\n",
    "\n",
    "    # Filter the dataframe to keep only instances for that language\n",
    "    df = df.query('language == @lan')\n",
    "    \n",
    "    # Add columns to keep LLM-response and eval score\n",
    "    df['llm_response'] = None\n",
    "    score_name = f\"score_{distance}\"\n",
    "    df[score_name] = None\n",
    "\n",
    "    \n",
    "    # Setup evaluator\n",
    "    if distance == \"cosine\":\n",
    "        dist_metric = EmbeddingDistance.COSINE\n",
    "    elif distance == \"euclidean\":\n",
    "        dist_metric = EmbeddingDistance.EUCLIDEAN\n",
    "\n",
    "    embedding_model = HuggingFaceEmbeddings()\n",
    "    hf_evaluator = load_evaluator(\"embedding_distance\", distance_metric=dist_metric, \n",
    "                              embeddings=embedding_model)\n",
    "    for idx, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        reference_response = row[ref_response_col]\n",
    "        llm_response = process_sql_query(question)\n",
    "        print('LLM-Response', \"===>\", llm_response)\n",
    "        if not llm_response:\n",
    "            print('Blank response')\n",
    "        score = hf_evaluator.evaluate_strings(prediction=llm_response, \n",
    "                                              reference=reference_response)\n",
    "        df.loc[idx, 'llm_response'] = llm_response\n",
    "        df.loc[idx, score_name] = score['score']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(DATABASE_URL)\n",
    "db = SQLDatabase(engine=engine, ignore_tables=['table_metadata', 'column_metadata'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1741"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_info = db.table_info\n",
    "len(table_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k5/p4nvl2pj4gq2ks0j7qvrhwbh0000gp/T/ipykernel_66207/747459483.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['llm_response'] = None\n",
      "/var/folders/k5/p4nvl2pj4gq2ks0j7qvrhwbh0000gp/T/ipykernel_66207/747459483.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[score_name] = None\n",
      "/Users/dunstanmatekenya/Library/CloudStorage/GoogleDrive-dmatekenya@gmail.com/My Drive/phosoAI-whatsapp-app-aws/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM-Response ===> The price of Maize in Rumphi is 764.45 Kwacha. This is the most recent price available in the database.\n",
      "LLM-Response ===> The price of rice in Lilongwe district is 1867.50 Kwacha per kg. This is the most recent price available in the database.\n",
      "LLM-Response ===> The district with the lowest price for groundnuts is Karonga, with a price of 1256.48 Kwacha.\n",
      "LLM-Response ===> Based on the SQL result, the locations where you can get cheap beans are Chikhwawa, Malomo, and Nchalo, where the price is 1200 Kwacha per kg. In comparison, Ngabu offers beans at a slightly higher price of 1300 Kwacha per kg, and Nkhata Bay has beans priced at 1336.486 Kwacha per kg.\n",
      "LLM-Response ===> Based on the SQL result, the cheapest place to buy Maize is Karonga with a price of 473.60 Kwacha per kg.\n",
      "LLM-Response ===> The best place to sell soya, based on the available data, is Mtakataka.\n",
      "LLM-Response ===> The most recent price of beans is 2704.91 Kwacha per kg.\n",
      "LLM-Response ===> The district that produced the most Maize is Lilongwe.\n",
      "LLM-Response ===> You can find a lot of rice to purchase in Karonga.\n",
      "LLM-Response ===> The crops that did well in Rumphi are:\n",
      "- Cassava with a total production of 93,696 kg\n",
      "- Maize with a total production of 77,748 kg\n",
      "- Sweet potatoes with a total production of 72,032 kg\n",
      "- Bananas with a total production of 38,746 kg\n",
      "- Mangoes with a total production of 29,432 kg\n",
      "\n",
      "This is the most recent data available.\n",
      "LLM-Response ===> The districts that harvested the most tobacco are Lilongwe, Dowa, Nkhotakota, Mchinji, and Rumphi.\n",
      "LLM-Response ===> Based on the available data, you can buy soya at the following locations:\n",
      "1. Farmer's Market\n",
      "2. Green Grocer's Store\n",
      "3. Organic Food Co-op\n",
      "\n",
      "Please note that this information is based on the latest data in the database.\n",
      "LLM-Response ===> The district that produced more maize between Lilongwe and Kasungu is Lilongwe, with a production of 444,440.0 kilograms.\n",
      "LLM-Response ===> The most recent price of maize in Dowa is 562.5 Kwacha per kg.\n",
      "LLM-Response ===> The districts where beans are cheap based on the most recent data are:\n",
      "1. Chikwawa: 1233.33 Kwacha per kg\n",
      "2. Ntchisi: 1841.65 Kwacha per kg\n",
      "\n",
      "These districts have relatively lower prices for beans compared to the other districts listed in the SQL result.\n",
      "LLM-Response ===> The cheapest rice is in Mzimba at 524 Kwacha per kg.\n",
      "LLM-Response ===> The cheapest groundnuts can be found in Nkhotakota at 1000.0 Kwacha per unit.\n",
      "LLM-Response ===> The most recent price of Maize in the country is 599.59 Kwacha per kg.\n",
      "LLM-Response ===> The most recent price of beans is 2704.91 Kwacha per kg.\n",
      "LLM-Response ===> The most recent price of Maize in Balaka is 633.265 Kwacha per kg.\n",
      "LLM-Response ===> The most recent price of Rice is 1817.40 Kwacha per kg.\n"
     ]
    }
   ],
   "source": [
    "df_eval = pd.read_csv(\"data/raw/eval-set.csv\")\n",
    "df_res = evaluate_with_embedding_distance(df=df_eval, lan='English', distance='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>language</th>\n",
       "      <th>response-1</th>\n",
       "      <th>response-2</th>\n",
       "      <th>llm_response</th>\n",
       "      <th>score_cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>How much is maize in Dowa?</td>\n",
       "      <td>English</td>\n",
       "      <td>Based on the most recent prices of May, 2024, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The price of maize in Dowa is 562.5 Kwacha per...</td>\n",
       "      <td>0.07533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Where can I buy soya?</td>\n",
       "      <td>English</td>\n",
       "      <td>You should look for soy beans in the following...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Based on the available data, you can buy soya ...</td>\n",
       "      <td>0.471374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Where is the best place to sale soya?</td>\n",
       "      <td>English</td>\n",
       "      <td>Based on the most recent prices of May 2024, s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The best place to sell soya, based on the avai...</td>\n",
       "      <td>0.345378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>current price of Maize in the country?</td>\n",
       "      <td>English</td>\n",
       "      <td>Based on the most recent prices of May 2024, t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The most recent price of Maize in the country ...</td>\n",
       "      <td>0.067668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  question language  \\\n",
       "13              How much is maize in Dowa?  English   \n",
       "11                   Where can I buy soya?  English   \n",
       "5    Where is the best place to sale soya?  English   \n",
       "17  current price of Maize in the country?  English   \n",
       "\n",
       "                                           response-1  response-2  \\\n",
       "13  Based on the most recent prices of May, 2024, ...         NaN   \n",
       "11  You should look for soy beans in the following...         NaN   \n",
       "5   Based on the most recent prices of May 2024, s...         NaN   \n",
       "17  Based on the most recent prices of May 2024, t...         NaN   \n",
       "\n",
       "                                         llm_response score_cosine  \n",
       "13  The price of maize in Dowa is 562.5 Kwacha per...      0.07533  \n",
       "11  Based on the available data, you can buy soya ...     0.471374  \n",
       "5   The best place to sell soya, based on the avai...     0.345378  \n",
       "17  The most recent price of Maize in the country ...     0.067668  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Whats the price of Maize?\"\n",
    "response = process_sql_query(user_question=question, llm=openai_chat_model)\n",
    "\n",
    "\n",
    "create_sql_prompt(examples, best_matching_table, columns_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
