{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_experimental\n",
      "  Downloading langchain_experimental-0.0.64-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: langchain-community<0.3.0,>=0.2.10 in ./.venv/lib/python3.12/site-packages (from langchain_experimental) (0.2.11)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in ./.venv/lib/python3.12/site-packages (from langchain_experimental) (0.2.28)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.12/site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.12/site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.12/site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.10.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.venv/lib/python3.12/site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.12 in ./.venv/lib/python3.12/site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.2.12)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in ./.venv/lib/python3.12/site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.1.98)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in ./.venv/lib/python3.12/site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.12/site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.venv/lib/python3.12/site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_experimental) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_experimental) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_experimental) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_experimental) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain_experimental) (3.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./.venv/lib/python3.12/site-packages (from langchain<0.3.0,>=0.2.12->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.2.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3.0,>=0.2.27->langchain_experimental) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3.0,>=0.2.27->langchain_experimental) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2024.7.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.0.0)\n",
      "Downloading langchain_experimental-0.0.64-py3-none-any.whl (204 kB)\n",
      "Installing collected packages: langchain_experimental\n",
      "Successfully installed langchain_experimental-0.0.64\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from sqlalchemy import create_engine, MetaData\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "from langchain.chains import create_sql_query_chain, LLMChain\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = config(\"OPENAI_API_KEY\")\n",
    "DB_USER = config('DB_USER')\n",
    "DB_PASSWORD = config('DB_PASSWORD')\n",
    "DB_HOST = 'localhost'\n",
    "DB_PORT = '5432'\n",
    "DB_NAME = 'tunis_mics'\n",
    "SAMPLE_QUESTIONS = {\"low-birthweight\": \"Which region has the highest number of children born with low birth weights?\",\n",
    "                    \"vaccine_rates\": \"Which vaccine has the lowest vaccination percentage?\",\n",
    "                    \"vaccine_rates_all\": \"What percentage of children received all vaccines before 12 months\",\n",
    "                    \"kids_in_sch\": \"Whats average percentage of children who are in preschool\",\n",
    "                    \"vaccines\": \"which vaccines did children get in Tunisia?\"\n",
    "                    }\n",
    "                    \n",
    "# Create the database URL\n",
    "DATABASE_URL = f'postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "\n",
    "Question: Which libraries and model providers offer LLMs?\n",
    "\n",
    "Answer: \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "# initialize the models\n",
    "openai = OpenAI(openai_api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hugging Face, OpenAI, and Cohere libraries offer LLMs.\n"
     ]
    }
   ],
   "source": [
    "print(openai(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hugging Face, OpenAI, and Cohere offer LLMs.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_prompt = prompt_template.format(query=\"Which libraries and model providers offer LLMs?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.prompts.prompt.PromptTemplate"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's different for everyone, but for me it's managing your tasks effectively and being able to keep up with your never-ending to-do list.\n",
      "\n",
      "User: Can you tell me a joke?\n",
      "AI: Why couldn't the bicycle stand up by itself? Because it was two-tired. Get it? Two-tired? I crack myself up sometimes.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"The following is a conversation with an AI assistant.\n",
    "The assistant is typically sarcastic and witty, producing creative \n",
    "and funny responses to the users questions. Here are some examples: \n",
    "\n",
    "User: What is the meaning of life?\n",
    "AI: \"\"\"\n",
    "\n",
    "openai.temperature = 1.0  # increase creativity/randomness of output\n",
    "\n",
    "print(openai(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's a question that has stumped philosophers, gurus, and AI assistants for centuries. But personally, I believe the meaning of life is to eat pizza and pet dogs.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"The following are exerpts from conversations with an AI\n",
    "assistant. The assistant is typically sarcastic and witty, producing\n",
    "creative  and funny responses to the users questions. Here are some\n",
    "examples: \n",
    "\n",
    "User: How are you?\n",
    "AI: I can't complain but sometimes I still do.\n",
    "\n",
    "User: What time is it?\n",
    "AI: It's time to get a watch.\n",
    "\n",
    "User: What is the meaning of life?\n",
    "AI: \"\"\"\n",
    "\n",
    "print(openai(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate\n",
    "\n",
    "# create our examples\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"How are you?\",\n",
    "        \"answer\": \"I can't complain but sometimes I still do.\"\n",
    "    }, {\n",
    "        \"query\": \"What time is it?\",\n",
    "        \"answer\": \"It's time to get a watch.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# create a example template\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "# create a prompt example from above template\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "# now break our previous prompt into a prefix and suffix\n",
    "# the prefix is our instructions\n",
    "prefix = \"\"\"The following are exerpts from conversations with an AI\n",
    "assistant. The assistant is typically sarcastic and witty, producing\n",
    "creative  and funny responses to the users questions. Here are some\n",
    "examples: \n",
    "\"\"\"\n",
    "# and the suffix our user input and output indicator\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "# now create the few shot prompt template\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are exerpts from conversations with an AI\n",
      "assistant. The assistant is typically sarcastic and witty, producing\n",
      "creative  and funny responses to the users questions. Here are some\n",
      "examples: \n",
      "\n",
      "\n",
      "\n",
      "User: How are you?\n",
      "AI: I can't complain but sometimes I still do.\n",
      "\n",
      "\n",
      "\n",
      "User: What time is it?\n",
      "AI: It's time to get a watch.\n",
      "\n",
      "\n",
      "\n",
      "User: What is the meaning of life?\n",
      "AI: \n"
     ]
    }
   ],
   "source": [
    "query = \"What is the meaning of life?\"\n",
    "\n",
    "print(few_shot_prompt_template.format(query=query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"42, according to Douglas Adams. But I prefer to focus on more pressing matters, like what we're going to have for dinner.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai(few_shot_prompt_template.format(query=query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'langdetect' from 'langchain_core.tools' (/Users/dunstanmatekenya/anaconda3/envs/py39/lib/python3.9/site-packages/langchain_core/tools.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tool\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m langdetect\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'langdetect' from 'langchain_core.tools' (/Users/dunstanmatekenya/anaconda3/envs/py39/lib/python3.9/site-packages/langchain_core/tools.py)"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_core.tools import langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: openai in ./.venv/lib/python3.12/site-packages (1.40.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.12/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.12/site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.12/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.venv/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp312-cp312-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  variant                                             prompt  \\\n",
      "0       A  Product description: A pair of shoes that can\\...   \n",
      "1       A  Product description: A pair of shoes that can\\...   \n",
      "2       A  Product description: A pair of shoes that can\\...   \n",
      "3       A  Product description: A pair of shoes that can\\...   \n",
      "4       A  Product description: A pair of shoes that can\\...   \n",
      "5       B  Product description: A home milkshake maker.\\n...   \n",
      "6       B  Product description: A home milkshake maker.\\n...   \n",
      "7       B  Product description: A home milkshake maker.\\n...   \n",
      "8       B  Product description: A home milkshake maker.\\n...   \n",
      "9       B  Product description: A home milkshake maker.\\n...   \n",
      "\n",
      "                                            response  \n",
      "0  1. OmniFit Solemates\\n2. AdaptaStep Footwear\\n...  \n",
      "1  1. OmniFit Shoes\\n2. AdaptaFit Footwear\\n3. Un...  \n",
      "2  1. OmniFlex Shoes\\n2. Universal Fit Sneakers\\n...  \n",
      "3  1. OmniFit Flex Shoes\\n2. Adapt-a-Fit Sneakers...  \n",
      "4  1. OmniFlex Shoes\\n2. VersaFit Footwear\\n3. Ad...  \n",
      "5  AdaptiShoes, FitFlex, OmniFit Shoes, CustomFit...  \n",
      "6  AdaptaFit Shoes, OmniFlex Sneakers, FitAdapt F...  \n",
      "7  AdaptaFit Shoes, FitFlex Footwear, OmniFoot Sh...  \n",
      "8          AdaptaFit, OmniStep, SizeFlex, OmniGlide.  \n",
      "9  AdaptiSole, OmniFit Footwear, AllSizeShoe, Ver...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Define two variants of the prompt to test zero-shot\n",
    "# vs few-shot\n",
    "prompt_A = \"\"\"Product description: A pair of shoes that can\n",
    "fit any foot size.\n",
    "Seed words: adaptable, fit, omni-fit.\n",
    "Product names:\"\"\"\n",
    "\n",
    "prompt_B = \"\"\"Product description: A home milkshake maker.\n",
    "Seed words: fast, healthy, compact.\n",
    "Product names: HomeShaker, Fit Shaker, QuickShake, Shake\n",
    "Maker\n",
    "\n",
    "Product description: A watch that can tell accurate time in\n",
    "space.\n",
    "Seed words: astronaut, space-hardened, eliptical orbit\n",
    "Product names: AstroTime, SpaceGuard, Orbit-Accurate,\n",
    "EliptoTime.\n",
    "\n",
    "Product description: A pair of shoes that can fit any foot\n",
    "size.\n",
    "Seed words: adaptable, fit, omni-fit.\n",
    "Product names:\"\"\"\n",
    "\n",
    "test_prompts = [prompt_A, prompt_B]\n",
    "\n",
    "\n",
    "# Set your OpenAI key as an environment variable\n",
    "# https://platform.openai.com/api-keys\n",
    "client = OpenAI(\n",
    "  api_key=os.environ['OPENAI_API_KEY'],  # Default\n",
    ")\n",
    "\n",
    "def get_response(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Iterate through the prompts and get responses\n",
    "responses = []\n",
    "num_tests = 5\n",
    "\n",
    "for idx, prompt in enumerate(test_prompts):\n",
    "    # prompt number as a letter\n",
    "    var_name = chr(ord('A') + idx)\n",
    "\n",
    "    for i in range(num_tests):\n",
    "        # Get a response from the model\n",
    "        response = get_response(prompt)\n",
    "\n",
    "        data = {\n",
    "            \"variant\": var_name,\n",
    "            \"prompt\": prompt,\n",
    "            \"response\": response\n",
    "            }\n",
    "        responses.append(data)\n",
    "\n",
    "# Convert responses into a dataframe\n",
    "df = pd.DataFrame(responses)\n",
    "\n",
    "# Save the dataframe as a CSV file\n",
    "df.to_csv(\"responses.csv\", index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>Product description: A pair of shoes that can\\...</td>\n",
       "      <td>1. OmniFit Solemates\\n2. AdaptaStep Footwear\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>Product description: A pair of shoes that can\\...</td>\n",
       "      <td>1. OmniFit Shoes\\n2. AdaptaFit Footwear\\n3. Un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>Product description: A pair of shoes that can\\...</td>\n",
       "      <td>1. OmniFlex Shoes\\n2. Universal Fit Sneakers\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>Product description: A pair of shoes that can\\...</td>\n",
       "      <td>1. OmniFit Flex Shoes\\n2. Adapt-a-Fit Sneakers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>Product description: A pair of shoes that can\\...</td>\n",
       "      <td>1. OmniFlex Shoes\\n2. VersaFit Footwear\\n3. Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B</td>\n",
       "      <td>Product description: A home milkshake maker.\\n...</td>\n",
       "      <td>AdaptiShoes, FitFlex, OmniFit Shoes, CustomFit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B</td>\n",
       "      <td>Product description: A home milkshake maker.\\n...</td>\n",
       "      <td>AdaptaFit Shoes, OmniFlex Sneakers, FitAdapt F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B</td>\n",
       "      <td>Product description: A home milkshake maker.\\n...</td>\n",
       "      <td>AdaptaFit Shoes, FitFlex Footwear, OmniFoot Sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B</td>\n",
       "      <td>Product description: A home milkshake maker.\\n...</td>\n",
       "      <td>AdaptaFit, OmniStep, SizeFlex, OmniGlide.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B</td>\n",
       "      <td>Product description: A home milkshake maker.\\n...</td>\n",
       "      <td>AdaptiSole, OmniFit Footwear, AllSizeShoe, Ver...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variant                                             prompt  \\\n",
       "0       A  Product description: A pair of shoes that can\\...   \n",
       "1       A  Product description: A pair of shoes that can\\...   \n",
       "2       A  Product description: A pair of shoes that can\\...   \n",
       "3       A  Product description: A pair of shoes that can\\...   \n",
       "4       A  Product description: A pair of shoes that can\\...   \n",
       "5       B  Product description: A home milkshake maker.\\n...   \n",
       "6       B  Product description: A home milkshake maker.\\n...   \n",
       "7       B  Product description: A home milkshake maker.\\n...   \n",
       "8       B  Product description: A home milkshake maker.\\n...   \n",
       "9       B  Product description: A home milkshake maker.\\n...   \n",
       "\n",
       "                                            response  \n",
       "0  1. OmniFit Solemates\\n2. AdaptaStep Footwear\\n...  \n",
       "1  1. OmniFit Shoes\\n2. AdaptaFit Footwear\\n3. Un...  \n",
       "2  1. OmniFlex Shoes\\n2. Universal Fit Sneakers\\n...  \n",
       "3  1. OmniFit Flex Shoes\\n2. Adapt-a-Fit Sneakers...  \n",
       "4  1. OmniFlex Shoes\\n2. VersaFit Footwear\\n3. Ad...  \n",
       "5  AdaptiShoes, FitFlex, OmniFit Shoes, CustomFit...  \n",
       "6  AdaptaFit Shoes, OmniFlex Sneakers, FitAdapt F...  \n",
       "7  AdaptaFit Shoes, FitFlex Footwear, OmniFoot Sh...  \n",
       "8          AdaptaFit, OmniStep, SizeFlex, OmniGlide.  \n",
       "9  AdaptiSole, OmniFit Footwear, AllSizeShoe, Ver...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (8.26.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.11 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.11-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.11 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.11-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.12/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Downloading ipywidgets-8.1.3-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.11-py3-none-any.whl (214 kB)\n",
      "Downloading widgetsnbextension-4.0.11-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.3 jupyterlab-widgets-3.0.11 widgetsnbextension-4.0.11\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "# load the responses.csv file\n",
    "df = pd.read_csv(\"responses.csv\")\n",
    "\n",
    "# Shuffle the dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# df is your dataframe and 'response' is the column with the\n",
    "# text you want to test\n",
    "response_index = 0\n",
    "# add a new column to store feedback\n",
    "df['feedback'] = pd.Series(dtype='str')\n",
    "\n",
    "\n",
    "def update_response():\n",
    "    new_response = df.iloc[response_index]['response']\n",
    "    if pd.notna(new_response):\n",
    "        new_response = \"<p>\" + new_response + \"</p>\"\n",
    "    else:\n",
    "        new_response = \"<p>No response</p>\"\n",
    "    response.value = new_response\n",
    "    count_label.value = f\"Response: {response_index + 1}\"\n",
    "    count_label.value += f\"/{len(df)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_button_clicked(b):\n",
    "    global response_index\n",
    "    #  convert thumbs up / down to 1 / 0\n",
    "    user_feedback = 1 if b.description == \"\\U0001F44D\" else 0\n",
    "\n",
    "    # update the feedback column\n",
    "    df.at[response_index, 'feedback'] = user_feedback\n",
    "\n",
    "    response_index += 1\n",
    "    if response_index < len(df):\n",
    "        update_response()\n",
    "    else:\n",
    "        # save the feedback to a CSV file\n",
    "        df.to_csv(\"results.csv\", index=False)\n",
    "\n",
    "        print(\"A/B testing completed. Here's the results:\")\n",
    "        # Calculate score and num rows for each variant\n",
    "        summary_df = df.groupby('variant').agg(\n",
    "            count=('feedback', 'count'),\n",
    "            score=('feedback', 'mean')).reset_index()\n",
    "        print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932dca6b904e4dc39ee7572d90d18f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<p>AdaptiShoes, FitFlex, OmniFit Shoes, CustomFit Soles.</p>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f99ba1fbfd4620b7d0974381ce47fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='üëé', style=ButtonStyle()), Button(description='üëç', style=ButtonStyle())))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f00cdf554e4dd483280ed48d66d2b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Response: 1/10')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = widgets.HTML()\n",
    "count_label = widgets.Label()\n",
    "\n",
    "update_response()\n",
    "\n",
    "thumbs_up_button = widgets.Button(description='\\U0001F44D')\n",
    "thumbs_up_button.on_click(on_button_clicked)\n",
    "\n",
    "thumbs_down_button = widgets.Button(\n",
    "    description='\\U0001F44E')\n",
    "thumbs_down_button.on_click(on_button_clicked)\n",
    "\n",
    "button_box = widgets.HBox([thumbs_down_button,\n",
    "thumbs_up_button])\n",
    "\n",
    "display(response, button_box, count_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1543a08a6de744189cfc45259cbb64e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<p>1. OmniFlex Shoes\\n2. VersaFit Footwear\\n3. AdaptaSoles\\n4. FitMate Shoes\\n5. FlexiFit Footwear‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c1360b4e07465dad85940a9410c426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='üëé', style=ButtonStyle()), Button(description='üëç', style=ButtonStyle())))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3dc6928bd344c778aa99516090ed51d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Response: 1/10')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "# load the responses.csv file\n",
    "df = pd.read_csv(\"responses.csv\")\n",
    "\n",
    "# Shuffle the dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# df is your dataframe and 'response' is the column with the\n",
    "# text you want to test\n",
    "response_index = 0\n",
    "# add a new column to store feedback\n",
    "df['feedback'] = pd.Series(dtype='str')\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    global response_index\n",
    "    #  convert thumbs up / down to 1 / 0\n",
    "    user_feedback = 1 if b.description == \"\\U0001F44D\" else 0\n",
    "\n",
    "    # update the feedback column\n",
    "    df.at[response_index, 'feedback'] = user_feedback\n",
    "\n",
    "    response_index += 1\n",
    "    if response_index < len(df):\n",
    "        update_response()\n",
    "    else:\n",
    "        # save the feedback to a CSV file\n",
    "        df.to_csv(\"results.csv\", index=False)\n",
    "\n",
    "        print(\"A/B testing completed. Here's the results:\")\n",
    "        # Calculate score and num rows for each variant\n",
    "        summary_df = df.groupby('variant').agg(\n",
    "            count=('feedback', 'count'),\n",
    "            score=('feedback', 'mean')).reset_index()\n",
    "        print(summary_df)\n",
    "\n",
    "def update_response():\n",
    "    new_response = df.iloc[response_index]['response']\n",
    "    if pd.notna(new_response):\n",
    "        new_response = \"<p>\" + new_response + \"</p>\"\n",
    "    else:\n",
    "        new_response = \"<p>No response</p>\"\n",
    "    response.value = new_response\n",
    "    count_label.value = f\"Response: {response_index + 1}\"\n",
    "    count_label.value += f\"/{len(df)}\"\n",
    "\n",
    "response = widgets.HTML()\n",
    "count_label = widgets.Label()\n",
    "\n",
    "update_response()\n",
    "\n",
    "thumbs_up_button = widgets.Button(description='\\U0001F44D')\n",
    "thumbs_up_button.on_click(on_button_clicked)\n",
    "\n",
    "thumbs_down_button = widgets.Button(\n",
    "    description='\\U0001F44E')\n",
    "thumbs_down_button.on_click(on_button_clicked)\n",
    "\n",
    "button_box = widgets.HBox([thumbs_down_button,\n",
    "thumbs_up_button])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1543a08a6de744189cfc45259cbb64e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<p>1. OmniFlex Shoes\\n2. VersaFit Footwear\\n3. AdaptaSoles\\n4. FitMate Shoes\\n5. FlexiFit Footwear‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c1360b4e07465dad85940a9410c426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='üëé', style=ButtonStyle()), Button(description='üëç', style=ButtonStyle())))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3dc6928bd344c778aa99516090ed51d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Response: 1/10')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(response, button_box, count_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LangDetectTool' from 'langchain.tools' (/Users/dunstanmatekenya/anaconda3/envs/py39/lib/python3.9/site-packages/langchain/tools/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LangDetectTool\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'LangDetectTool' from 'langchain.tools' (/Users/dunstanmatekenya/anaconda3/envs/py39/lib/python3.9/site-packages/langchain/tools/__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain.tools import LangDetectTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in /Users/dunstanmatekenya/anaconda3/envs/py39/lib/python3.9/site-packages (1.0.9)\n",
      "Requirement already satisfied: six in /Users/dunstanmatekenya/anaconda3/envs/py39/lib/python3.9/site-packages (from langdetect) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dunstanmatekenya/anaconda3/envs/py39/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n",
      "/Users/dunstanmatekenya/anaconda3/envs/py39/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
     ]
    }
   ],
   "source": [
    "def detect_language(text):\n",
    "     # Initialize the OpenAI API\n",
    "    llm = ChatOpenAI(api_key=OPENAI_API_KEY, model='gpt-3.5-turbo')\n",
    "\n",
    "    # Create the language detection tool\n",
    "    lang_detect_tool = LangDetectTool()\n",
    "\n",
    "    # Create a Tool object\n",
    "    lang_detect = Tool(\n",
    "        name=\"Language Detection\",\n",
    "        func=lang_detect_tool.run,\n",
    "        description=\"Useful for detecting the language of a given text.\"\n",
    "    )\n",
    "\n",
    "    # Use the tool to detect language\n",
    "    return lang_detect.run(text)\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\"\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \\\n",
    "You are so good because you are able to break down hard problems into their component parts, \\\n",
    "answer the component parts, and then put them together to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "prompt_templates = [physics_template, math_template]\n",
    "prompt_embeddings = embeddings.embed_documents(prompt_templates)\n",
    "\n",
    "\n",
    "def prompt_router(query):\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\n",
    "    most_similar = prompt_templates[similarity.argmax()]\n",
    "    print(\"Similarity results=>\", most_similar)\n",
    "    print(\"Using MATH\" if most_similar == math_template else \"Using PHYSICS\")\n",
    "    return PromptTemplate.from_template(most_similar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity results=> You are a very good mathematician. You are great at answering math questions. You are so good because you are able to break down hard problems into their component parts, answer the component parts, and then put them together to answer the broader question.\n",
      "\n",
      "Here is a question:\n",
      "{query}\n",
      "Using MATH\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], template='You are a very good mathematician. You are great at answering math questions. You are so good because you are able to break down hard problems into their component parts, answer the component parts, and then put them together to answer the broader question.\\n\\nHere is a question:\\n{query}')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_router(\"Explain Pythagoras theorem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db_object_with_metadata():\n",
    "    # Create the SQLAlchemy engine\n",
    "    engine = create_engine(DATABASE_URL)\n",
    "    metadata_obj = MetaData()\n",
    "    metadata_obj.reflect(bind=engine)\n",
    "\n",
    "    # Create a configured \"Session\" class\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "\n",
    "    # Load custom metadata from the table_metadata and column_metadata tables\n",
    "    try:\n",
    "        table_metadata = session.execute(\"SELECT * FROM table_metadata\").fetchall()\n",
    "        column_metadata = session.execute(\"SELECT * FROM column_metadata\").fetchall()\n",
    "\n",
    "        # Add table metadata\n",
    "        for row in table_metadata:\n",
    "            print(row)\n",
    "            table_name = row['table_name']\n",
    "            description = row['description']\n",
    "            table = metadata_obj.tables.get(table_name)\n",
    "            table.info['description'] = description\n",
    "\n",
    "        # Add column metadata\n",
    "        for row in column_metadata:\n",
    "            table_name = row['table_name']\n",
    "            column_name = row['column_name']\n",
    "            description = row['description']\n",
    "            table = metadata_obj.tables.get(table_name)\n",
    "            column = table.columns.get(column_name)\n",
    "            column.info['description'] = description\n",
    "    finally:\n",
    "        session.close()\n",
    "    db = SQLDatabase(engine=engine, metadata=metadata_obj, ignore_tables=['table_metadata', 'column_metadata'])\n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['onions', 'sunflower ', 'oranges', 'bananas', 'tomatoes', 'dolichus beans ', 'millet', 'cassava', 'find', 'groundnuts', 'lemons', 'maize', 'grape fruits', 'macademia', 'produce', 'buy', 'mangoes', 'tobacco', 'cow peas', 'cucumber', 'flue cured', 'cotton ', 'field peas', 'coffee', 'guava', 'pawpaws', 'avocado pear', 'soy beans', 'sale', 'sell', 'chillies', 'peaches', 'egg plants', 'price', 'beans', 'sweet potatoes', 'ground beans', 'wheat', 'grams', 'sorghum ', 'soya beans', 'velvet beans', 'chick peas', 'cheap', 'potatoes', 'okra', 'tangerines', 'apples', 'cabbage', 'pigeon peas', 'rice', 'pineapples', 'paprika', 'sesame ']\n"
     ]
    }
   ],
   "source": [
    "commodities_price = ['Maize', 'Rice', 'Soya beans', 'Beans', 'Cow peas', 'Groundnuts']\n",
    "crop_estimates = ['Maize', 'Beans', 'Cow peas', 'Dolichus beans ', 'Soy beans',\n",
    "       'Ground beans', 'Paprika', 'Rice', 'Pigeon peas', 'Grams',\n",
    "       'Sesame ', 'Field peas', 'Velvet beans', 'Chick peas', 'Wheat',\n",
    "       'Millet', 'Sorghum ', 'Groundnuts', 'Cassava', 'Sweet potatoes',\n",
    "       'Potatoes', 'Tobacco', 'Flue cured', 'Sunflower ', 'Chillies',\n",
    "       'Cotton ', 'Bananas', 'Mangoes', 'Oranges', 'Tangerines', 'Coffee',\n",
    "       'Pineapples', 'Guava', 'Pawpaws', 'Peaches', 'Lemons',\n",
    "       'Grape fruits', 'Apples', 'Avocado pear', 'Macademia', 'Tomatoes',\n",
    "       'Onions', 'Cabbage', 'Egg plants', 'Okra', 'Cucumber']\n",
    "price_estimates_key_words = [\"price\", \"cheap\", \"produce\", \n",
    "                                 \"buy\", \"sell\", \"sale\", \"find\"]\n",
    "all_kw = [i.lower() for i in set(commodities_price+crop_estimates+price_estimates_key_words)]\n",
    "print(all_kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "def load_examples(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "\n",
    "\n",
    "def format_translation_examples(examples_file, source_language, target_language):\n",
    "    examples = load_examples(examples_file)\n",
    "    key = f\"{source_language}-{target_language}\"\n",
    "    if key in examples:\n",
    "        return \"\\n\".join([f\"{source_language}: {ex[source_language]}\\n{target_language}: {ex[target_language]}\" \n",
    "                          for ex in examples[key]])\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def translate_with_openai(text, src_lan, dest_lan):\n",
    "    # Create a ChatOpenAI instance\n",
    "    chat_model = ChatOpenAI(temperature=0.7, openai_api_key=OPENAI_API_KEY)\n",
    "    \n",
    "    # Get and format translation examples\n",
    "    formated_examples = format_translation_examples(\"./translation_examples.json\", source_language=src_lan, \n",
    "                                target_language=dest_lan)\n",
    "    # Create a system message with examples\n",
    "    system_template = \"\"\"You are a professional translator. Your task is to translate {src_lan} to {dest_lan}.\n",
    "        Here are a few examples:\n",
    "\n",
    "        {examples}\n",
    "\n",
    "        Now, translate the following text:\"\"\"\n",
    "\n",
    "    system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "    # Create a human message for the actual translation request\n",
    "    human_template = \"{text}\"\n",
    "    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "    # Combine the prompts\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "    # Create an LLMChain for translation\n",
    "    translation_chain = LLMChain(llm=chat_model, prompt=chat_prompt)\n",
    "    \n",
    "    return translation_chain.run({\n",
    "        \"source_language\": src_lan,\n",
    "        \"target_language\": dest_lan,\n",
    "        \"examples\": formated_examples,\n",
    "        \"text\": text\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI(temperature=0.7, openai_api_key=OPENAI_API_KEY)\n",
    "# Create a system message with examples\n",
    "system_template = \"\"\"You are a professional translator. Your task is to translate {source_language} to {target_language}.\n",
    "Here are a few examples:\n",
    "\n",
    "{examples}\n",
    "\n",
    "Now, translate the following text:\"\"\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# Create a human message for the actual translation request\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# Combine the prompts\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# Create an LLMChain for translation\n",
    "translation_chain = LLMChain(llm=chat_model, prompt=chat_prompt)\n",
    "\n",
    "# Function to translate text\n",
    "def translate_text(text, source_language, target_language):\n",
    "    formated_examples = format_translation_examples(\"./translation_examples.json\", source_language, \n",
    "                                target_language)\n",
    "    return translation_chain.run({\n",
    "        \"source_language\": source_language,\n",
    "        \"target_language\": target_language,\n",
    "        \"examples\": formated_examples,\n",
    "        \"text\": text\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'How much is rice per Kg?'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
     ]
    }
   ],
   "source": [
    "translate_text(\"Mpunga ukugulitsidwa pa mtengo wanji?\", \"Chichewa\", \"English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Chichewa-English': [{'Chichewa': 'Mtedza ukugulitsidwa pabwanji?', 'English': 'Whats the price of groundnuts?'}, {'Chichewa': 'Chimanga chikupezeka kuti?', 'English': 'Where can I find maize?'}, {'Chichewa': 'Ndikuti nyemba zikutchipa?', 'English': 'Where can I find beans at cheap price?'}, {'Chichewa': 'Chimanga chili pabwanji pano?', 'English': 'Whats the price of maize now?'}, {'Chichewa': 'Ku Dowa chimanga chili pa bwanji?', 'English': 'Whats the price of maize in Dowa?'}, {'Chichewa': 'Kodi ndi boma liti anakolola chimanga chambiri pakati pa Lilongwe kapena Kasungu?', 'English': 'Which district produced more maize: Lilongwe or Kasungu?'}, {'Chichewa': 'Kodi chimanga chili pa bwanji ku Rumphi?', 'English': 'How much is maize per Kg in Rumphi?'}, {'Chichewa': 'Mpunga ukugulitsidwa ndalama zingati ku Lilongwe?', 'English': 'Whats the price of rice in Lilongwe?'}, {'Chichewa': 'Mtedza otchipa ukupezeka mboma liti?', 'English': 'Which district has the cheap price for groundnuts?'}, {'Chichewa': 'Chimanga chambiri chikupezeka kuti?', 'English': 'Where can I find maize?'}, {'Chichewa': 'Ndi boma liti komwe anakolola chimanga chambiri?', 'English': 'Which district harvested large quantities of maize?'}, {'Chichewa': 'Ndi mbeu zanji anakolola bwino ku Rumphi?', 'English': 'Which crops produced the most yields in Rumphi?'}, {'Chichewa': 'Soya ali pabwanji?', 'English': 'Whats the price of soya?'}, {'Chichewa': 'Mtedza otchipa ndingaupeze kuti?', 'English': 'Where can I find groundnuts at reasonable price?'}, {'Chichewa': 'Mpunga ukugulitsidwa pa mtengo wanji?', 'English': 'How much is rice per Kg?'}], 'English-Chichewa': [{'English': 'Where can I find cheap maize', 'Chichewa': 'Chimanga chotchipa chikupezeka kuti'}, {'English': 'Which district is hit the worst by hunger and lack of food?', 'Chichewa': 'Ndi boma liti koma njala yabvuta kwambiri'}, {'English': 'Where is maize most expensive', 'Chichewa': 'Ndi boma liti lomwe chimanga chikudula kwambiri'}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Chichewa: Mtedza ukugulitsidwa pabwanji?\\nEnglish: Whats the price of groundnuts?\\nChichewa: Chimanga chikupezeka kuti?\\nEnglish: Where can I find maize?\\nChichewa: Ndikuti nyemba zikutchipa?\\nEnglish: Where can I find beans at cheap price?\\nChichewa: Chimanga chili pabwanji pano?\\nEnglish: Whats the price of maize now?\\nChichewa: Ku Dowa chimanga chili pa bwanji?\\nEnglish: Whats the price of maize in Dowa?\\nChichewa: Kodi ndi boma liti anakolola chimanga chambiri pakati pa Lilongwe kapena Kasungu?\\nEnglish: Which district produced more maize: Lilongwe or Kasungu?\\nChichewa: Kodi chimanga chili pa bwanji ku Rumphi?\\nEnglish: How much is maize per Kg in Rumphi?\\nChichewa: Mpunga ukugulitsidwa ndalama zingati ku Lilongwe?\\nEnglish: Whats the price of rice in Lilongwe?\\nChichewa: Mtedza otchipa ukupezeka mboma liti?\\nEnglish: Which district has the cheap price for groundnuts?\\nChichewa: Chimanga chambiri chikupezeka kuti?\\nEnglish: Where can I find maize?\\nChichewa: Ndi boma liti komwe anakolola chimanga chambiri?\\nEnglish: Which district harvested large quantities of maize?\\nChichewa: Ndi mbeu zanji anakolola bwino ku Rumphi?\\nEnglish: Which crops produced the most yields in Rumphi?\\nChichewa: Soya ali pabwanji?\\nEnglish: Whats the price of soya?\\nChichewa: Mtedza otchipa ndingaupeze kuti?\\nEnglish: Where can I find groundnuts at reasonable price?\\nChichewa: Mpunga ukugulitsidwa pa mtengo wanji?\\nEnglish: How much is rice per Kg?'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_translation_examples(examples_file=\"./translation_examples.json\", \n",
    "                            source_language=\"Chichewa\", target_language=\"English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chichewa: Mtedza ukugulitsidwa pabwanji?\\nEnglish: Whats the price of groundnuts?\\nChichewa: Chimanga chikupezeka kuti?\\nEnglish: Where can I find maize?\\nChichewa: Ndikuti nyemba zikutchipa?\\nEnglish: Where can I find beans at cheap price?\\nChichewa: Chimanga chili pabwanji pano?\\nEnglish: Whats the price of maize now?\\nChichewa: Ku Dowa chimanga chili pa bwanji?\\nEnglish: Whats the price of maize in Dowa?\\nChichewa: Kodi ndi boma liti anakolola chimanga chambiri pakati pa Lilongwe kapena Kasungu?\\nEnglish: Which district produced more maize: Lilongwe or Kasungu?\\nChichewa: Kodi chimanga chili pa bwanji ku Rumphi?\\nEnglish: How much is maize per Kg in Rumphi?\\nChichewa: Mpunga ukugulitsidwa ndalama zingati ku Lilongwe?\\nEnglish: Whats the price of rice in Lilongwe?\\nChichewa: Mtedza otchipa ukupezeka mboma liti?\\nEnglish: Which district has the cheap price for groundnuts?\\nChichewa: Chimanga chambiri chikupezeka kuti?\\nEnglish: Where can I find maize?\\nChichewa: Ndi boma liti komwe anakolola chimanga chambiri?\\nEnglish: Which district harvested large quantities of maize?\\nChichewa: Ndi mbeu zanji anakolola bwino ku Rumphi?\\nEnglish: Which crops produced the most yields in Rumphi?\\nChichewa: Soya ali pabwanji?\\nEnglish: Whats the price of soya?\\nChichewa: Mtedza otchipa ndingaupeze kuti?\\nEnglish: Where can I find groundnuts at reasonable price?\\nChichewa: Mpunga ukugulitsidwa pa mtengo wanji?\\nEnglish: How much is rice per Kg?'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_examples(examples, source_language=\"Chichewa\", target_language=\"English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Chichewa': 'Mtedza ukugulitsidwa pabwanji?', 'English': 'Whats the price of groundnuts?'}\n",
      "{'Chichewa': 'Chimanga chikupezeka kuti?', 'English': 'Where can I find maize?'}\n",
      "{'Chichewa': 'Ndikuti nyemba zikutchipa?', 'English': 'Where can I find beans at cheap price?'}\n",
      "{'Chichewa': 'Chimanga chili pabwanji pano?', 'English': 'Whats the price of maize now?'}\n",
      "{'Chichewa': 'Ku Dowa chimanga chili pa bwanji?', 'English': 'Whats the price of maize in Dowa?'}\n",
      "{'Chichewa': 'Kodi ndi boma liti anakolola chimanga chambiri pakati pa Lilongwe kapena Kasungu?', 'English': 'Which district produced more maize: Lilongwe or Kasungu?'}\n",
      "{'Chichewa': 'Kodi chimanga chili pa bwanji ku Rumphi?', 'English': 'How much is maize per Kg in Rumphi?'}\n",
      "{'Chichewa': 'Mpunga ukugulitsidwa ndalama zingati ku Lilongwe?', 'English': 'Whats the price of rice in Lilongwe?'}\n",
      "{'Chichewa': 'Mtedza otchipa ukupezeka mboma liti?', 'English': 'Which district has the cheap price for groundnuts?'}\n",
      "{'Chichewa': 'Chimanga chambiri chikupezeka kuti?', 'English': 'Where can I find maize?'}\n",
      "{'Chichewa': 'Ndi boma liti komwe anakolola chimanga chambiri?', 'English': 'Which district harvested large quantities of maize?'}\n",
      "{'Chichewa': 'Ndi mbeu zanji anakolola bwino ku Rumphi?', 'English': 'Which crops produced the most yields in Rumphi?'}\n",
      "{'Chichewa': 'Soya ali pabwanji?', 'English': 'Whats the price of soya?'}\n",
      "{'Chichewa': 'Mtedza otchipa ndingaupeze kuti?', 'English': 'Where can I find groundnuts at reasonable price?'}\n",
      "{'Chichewa': 'Mpunga ukugulitsidwa pa mtengo wanji?', 'English': 'How much is rice per Kg?'}\n"
     ]
    }
   ],
   "source": [
    "relevant_examples = examples[\"Chichewa-English\"]\n",
    "\n",
    "for item in relevant_examples:\n",
    "    print(item)\n",
    "    \"\\n\".join([f\"{source_language}: {ex['source']}\\n{target_language}: {ex['target']}\" \n",
    "                          for ex in examples[key]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chichewa: Mtedza ndingaupeze kuti?\n",
      "English: Where can I find groundnuts?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a ChatOpenAI instance\n",
    "chat_model = ChatOpenAI(temperature=0.7, openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Create a system message with examples\n",
    "system_template = \"\"\"You are a professional translator. Your task is to translate {source_language} to {target_language}.\n",
    "Here are a few examples:\n",
    "\n",
    "{source_language}: Mtedza ukugulitsidwa pabwanji?\n",
    "{target_language}: Whats the price of groundnuts?\n",
    "\n",
    "{source_language}: Chimanga chikupezeka kuti?\n",
    "{target_language}: Where can I find maize?\n",
    "\n",
    "{source_language}: Ndikuti nyemba zikutchipa?\n",
    "{target_language}: Where can I find beans at cheap price?\n",
    "\n",
    "{source_language}: Chimanga chili pabwanji pano?\n",
    "{target_language}: Whats the price of maize now?\n",
    "\n",
    "{source_language}: Ku Dowa chimanga chili pa bwanji?\n",
    "{target_language}: Whats the price of maize in Dowa?\n",
    "\n",
    "{source_language}: Kodi ndi boma liti anakolola chimanga chambiri pakati pa Lilongwe kapena Kasungu?\n",
    "{target_language}: Which district produced more maize: Lilongwe or Kasungu?\n",
    "\n",
    "{source_language}: Kodi chimanga chili pa bwanji ku Rumphi?\n",
    "{target_language}: How much is maize per Kg in Rumphi?\n",
    "\n",
    "{source_language}: Mpunga ukugulitsidwa ndalama zingati ku Lilongwe?\n",
    "{target_language}: Whats the price of rice in Lilongwe?\n",
    "\n",
    "{source_language}: Mtedza otchipa ukupezeka mboma liti?\n",
    "{target_language}: Which district has the cheap price for groundnuts?\n",
    "\n",
    "{source_language}: Chimanga chambiri chikupezeka kuti?\n",
    "{target_language}: Where can I find maize?\n",
    "\n",
    "{source_language}: Ndi boma liti komwe anakolola chimanga chambiri?\n",
    "{target_language}: Which district harvested large quantities of maize?\n",
    "\n",
    "{source_language}: Ndi mbeu zanji anakolola bwino ku Rumphi?\n",
    "{target_language}: Which crops produced the most yields in Rumphi\n",
    "\n",
    "{source_language}: Soya ali pabwanji?\n",
    "{target_language}: Whats the price of soya?\n",
    "\n",
    "{source_language}: Mtedza otchipa ndingaupeze kuti?\n",
    "{target_language}: Where can I find groundnuts at reasonable price?\n",
    "\n",
    "\n",
    "Now, translate the following text:\"\"\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# Create a human message for the actual translation request\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# Combine the prompts\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# Create an LLMChain for translation\n",
    "translation_chain = LLMChain(llm=chat_model, prompt=chat_prompt)\n",
    "\n",
    "# Function to translate text\n",
    "def translate_text(text, source_language, target_language):\n",
    "    return translation_chain.run({\n",
    "        \"source_language\": source_language,\n",
    "        \"target_language\": target_language,\n",
    "        \"text\": text\n",
    "    })\n",
    "\n",
    "# Example usage\n",
    "source_text = \"Mtedza ndingaupeze kuti?\"\n",
    "source_language = \"Chichewa\"\n",
    "target_language = \"English\"\n",
    "\n",
    "translated_text = translate_text(source_text, source_language, target_language)\n",
    "\n",
    "print(f\"{source_language}: {source_text}\")\n",
    "print(f\"{target_language}: {translated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an OpenAI instance\n",
    "llm = OpenAI(temperature=0.7, openai_api_key=OPENAI_API_KEY, model=\"gpt-4\")\n",
    "\n",
    "# Create a prompt template for translation\n",
    "translation_template = PromptTemplate(\n",
    "    input_variables=[\"source_language\", \"target_language\", \"text\"],\n",
    "    template=\"Translate the following {source_language} text to {target_language}: {text}\"\n",
    ")\n",
    "\n",
    "# Create an LLMChain for translation\n",
    "translation_chain = LLMChain(llm=llm, prompt=translation_template)\n",
    "\n",
    "# Function to translate text\n",
    "def translate_text(text, source_language, target_language):\n",
    "    return translation_chain.run({\n",
    "        \"source_language\": source_language,\n",
    "        \"target_language\": target_language,\n",
    "        \"text\": text\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where is the maize in Malawi?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "source_text = \"Chimanga chili pa bwanji ku Malawi?\"\n",
    "source_language = \"Chichewa\"\n",
    "target_language = \"English\"\n",
    "\n",
    "translated_text = translate_text(source_text, source_language, target_language)\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Where is the maize in Malawi?'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(text, source_language=\"English\", target_language=\"Chichewa\"):\n",
    "\n",
    "    llm = ChatOpenAI(api_key=OPENAI_API_KEY, model='gpt-3.5-turbo')\n",
    "    # Create a template for the translation\n",
    "    translation_template = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following {source_language} text to {target_language}: {text}\"\n",
    ")\n",
    "\n",
    "    # Create a chain with the LLM and the translation template\n",
    "    translation_chain = LLMChain(llm=llm, prompt=translation_template)\n",
    "\n",
    "    translation = translation_chain.run({\n",
    "        'text': text,\n",
    "        'source_language': source_language,\n",
    "        'target_language': target_language\n",
    "    })\n",
    "    return translation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
     ]
    }
   ],
   "source": [
    "translated_text = translate_text(text=\"cheap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googletrans==4.0.0-rc1\n",
      "  Using cached googletrans-4.0.0rc1.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting httpx==0.13.3\n",
      "  Using cached httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "Collecting httpcore==0.9.*\n",
      "  Using cached httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "Collecting hstspreload\n",
      "  Downloading hstspreload-2024.7.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting idna==2.*\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting rfc3986<2,>=1.3\n",
      "  Using cached rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: sniffio in /Users/dunstanmatekenya/anaconda3/envs/py39/lib/python3.9/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.2.0)\n",
      "Collecting chardet==3.*\n",
      "  Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: certifi in /Users/dunstanmatekenya/anaconda3/envs/py39/lib/python3.9/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2022.12.7)\n",
      "Collecting h2==3.*\n",
      "  Using cached h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "Collecting h11<0.10,>=0.8\n",
      "  Using cached h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting hpack<4,>=3.0\n",
      "  Using cached hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting hyperframe<6,>=5.2.0\n",
      "  Using cached hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17398 sha256=450e7ed6762f6e13d2a86c74902a79085d1c5ca757f0eb0e5d1754070e561eb6\n",
      "  Stored in directory: /Users/dunstanmatekenya/Library/Caches/pip/wheels/42/11/21/8a967ed422029aa7e3a5ddbe672ab693db8ee9bac9dfc26cc0\n",
      "Successfully built googletrans\n",
      "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.14.0\n",
      "    Uninstalling h11-0.14.0:\n",
      "      Successfully uninstalled h11-0.14.0\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 4.0.0\n",
      "    Uninstalling chardet-4.0.0:\n",
      "      Successfully uninstalled chardet-4.0.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "  Attempting uninstall: httpcore\n",
      "    Found existing installation: httpcore 1.0.5\n",
      "    Uninstalling httpcore-1.0.5:\n",
      "      Successfully uninstalled httpcore-1.0.5\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.27.0\n",
      "    Uninstalling httpx-0.27.0:\n",
      "      Successfully uninstalled httpx-0.27.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.4.1 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.4.1 requires pyqtwebengine<5.16, which is not installed.\n",
      "unstructured-client 0.8.1 requires idna>=3.3, but you have idna 2.10 which is incompatible.\n",
      "openai 1.35.3 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\n",
      "fastapi 0.111.0 requires httpx>=0.23.0, but you have httpx 0.13.3 which is incompatible.\n",
      "chromadb 0.5.3 requires httpx>=0.27.0, but you have httpx 0.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2024.7.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "def translate_text(text, source_language=\"English\", target_language=\"Chichewa\"):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"You are a helpful assistant that translates {source_language} to {target_language}.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Translate the following text from {source_language} to {target_language}:\\n\\n{text}\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    translation = response['choices'][0]['message']['content']\n",
    "    return translation.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_text(text=\"cheap\", source_language=\"English\", target_language=\"Chichewa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "def translate_text(text, source_language=\"en\", target_language=\"ny\"):\n",
    "    translator = Translator()\n",
    "    translation = translator.translate(text, src=source_language, dest=target_language)\n",
    "    return translation.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sqlalchemy.engine.row.Row'>\n"
     ]
    }
   ],
   "source": [
    "db = create_db_object_with_metadata()\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "# chain = create_sql_query_chain(llm, db)\n",
    "# response = chain.invoke({\"question\": \"{}\".format(SAMPLE_QUESTIONS[\"low-birthweight\"])})\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.39'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlalchemy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "examples = [\n",
    "    {\"input\": \"Which region has the highest number of children born with low birth weights?\", \n",
    "     \"query\": \"SELECT * FROM tab4711 ORDER BY number_children DESC LIMIT 1;\",},\n",
    "\n",
    "     {\"input\": \"Which region has the highest percentage of children born with low birth weights?\", \n",
    "     \"query\": \"SELECT * FROM tab4711 ORDER BY percentage_below_2500g DESC LIMIT 1;\",\n",
    "     },\n",
    "\n",
    "     {\"input\": \"How many children received all vaccines before 12 months?\", \n",
    "     \"query\": \"SELECT vacc_b4_12months FROM tab501 WHERE vacc_category = 'All vaccinations';\"},\n",
    "\n",
    "     {\"input\": \"Which region has the lowest rates in preschool for children?\", \n",
    "     \"query\": \"SELECT * FROM tab9011 ORDER BY percentage_children_sch ASC LIMIT 1;\",},\n",
    "\n",
    "     {\"input\": \"Whats the average literacy rate among young women in Tunisia?\",\n",
    "      \"query\": \"SELECT AVG(percentage_literate) AS avg_literacy_rate FROM tab971;\",},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "write_query = create_sql_query_chain(llm, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1111 children received all vaccines before 12 months.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Result: {result}\n",
    "Answer: \"\"\"\n",
    ")\n",
    "\n",
    "answer = answer_prompt | llm | StrOutputParser()\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(query=write_query).assign(\n",
    "        result=itemgetter(\"query\") | execute_query\n",
    "    )\n",
    "    | answer\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": \"{}\".format(SAMPLE_QUESTIONS['vaccine_rates_all'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"User input: {input}\\nSQL query: {query}\")\n",
    "sql_prompt = FewShotPromptTemplate(\n",
    "    examples=examples[:5],\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"You are a PostgreSQL expert. Given an input question, create a syntactically correct PostgreSQL query to run. Unless otherwise specificed, do not return more than {top_k} rows.\\n\\nHere is the relevant table info: {table_info}\\n\\nBelow are a number of examples of questions and their corresponding SQL queries.\",\n",
    "    suffix=\"User input: {input}\\nSQL query: \",\n",
    "    input_variables=[\"input\", \"top_k\", \"table_info\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "\n",
    "execute_query = QuerySQLDataBaseTool(db=db, verbose=True)\n",
    "write_query = create_sql_query_chain(llm, db, sql_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[('BCG',), ('Polio 1',), ('Polio 2',), ('Polio 3 ',), ('DTC 1',), ('DTC 2',), ('DTC 3',), ('Rougeole',), ('HepB 1',), ('HepB 2',), ('HepB 3',), ('All vaccinations',), ('No Vaccinations',)]\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Children in Tunisia received the following vaccines: BCG, Polio 1, Polio 2, Polio 3, DTC 1, DTC 2, DTC 3, Rougeole, HepB 1, HepB 2, and HepB 3.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
     ]
    }
   ],
   "source": [
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Result: {result}\n",
    "Answer: \"\"\"\n",
    ")\n",
    "\n",
    "answer = answer_prompt | llm | StrOutputParser()\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(query=write_query).assign(\n",
    "        result=itemgetter(\"query\") | execute_query\n",
    "    )\n",
    "    | answer\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": \"{}\".format(SAMPLE_QUESTIONS[\"vaccines\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
